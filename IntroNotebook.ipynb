{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU utilizations\n",
    "the following code shows you how much GPUs are utilzied. \n",
    "I would choose GPU which has the most free Memory, e.g.\n",
    "11MiB / 11439MiB tells you that only 11MiBs are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    89W / 149W |    652MiB / 11439MiB |     92%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K80           Off  | 00000000:05:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    97W / 149W |    943MiB / 11439MiB |     87%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla K80           Off  | 00000000:83:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    61W / 149W |  11374MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla K80           Off  | 00000000:84:00.0 Off |                    0 |\n",
      "| N/A   49C    P0   150W / 149W |   6381MiB / 11439MiB |     96%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi | grep -A 2 -B 2 \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"  # which GPU are we using (from 0 to 3)\n",
    "import torch\n",
    "torch.set_num_threads(2)\n",
    "device=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000 \n",
    "a = torch.zeros([n,n]).to(device)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset= datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "epochs=10\n",
    "train_load=torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,num_workers=2)\n",
    "test_load=torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in training set: 60000\n",
      "Number of images in test set: 10000\n",
      "Number of batches in the train loader: 600\n",
      "Number of batches in the test loader: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images in training set: {}\".format(len(train_dataset)))\n",
    "print(\"Number of images in test set: {}\".format(len(test_dataset)))\n",
    "print(\"Number of batches in the train loader: {}\".format(len(train_load)))\n",
    "print(\"Number of batches in the test loader: {}\".format(len(test_load)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.2980, -0.3001, -0.0216],\n",
      "          [ 0.2505,  0.0374,  0.1989],\n",
      "          [ 0.3172, -0.1678, -0.2354]]],\n",
      "\n",
      "\n",
      "        [[[-0.0437,  0.1325,  0.2589],\n",
      "          [-0.1574, -0.1561, -0.2417],\n",
      "          [-0.0260,  0.1626, -0.3100]]],\n",
      "\n",
      "\n",
      "        [[[-0.2385, -0.0629,  0.0227],\n",
      "          [ 0.0575, -0.2354, -0.1360],\n",
      "          [-0.1508,  0.1574,  0.2745]]],\n",
      "\n",
      "\n",
      "        [[[-0.1811, -0.2940, -0.1910],\n",
      "          [-0.0098,  0.1716, -0.0090],\n",
      "          [-0.2765,  0.2010,  0.1643]]],\n",
      "\n",
      "\n",
      "        [[[-0.0962, -0.0630, -0.3145],\n",
      "          [-0.0620, -0.1136, -0.1233],\n",
      "          [ 0.0276, -0.1000, -0.1335]]],\n",
      "\n",
      "\n",
      "        [[[-0.0280, -0.1061, -0.0684],\n",
      "          [-0.1077, -0.0805, -0.2235],\n",
      "          [-0.3329,  0.0497, -0.1480]]],\n",
      "\n",
      "\n",
      "        [[[-0.0531,  0.1734, -0.1789],\n",
      "          [-0.1540, -0.0209,  0.2476],\n",
      "          [-0.0416,  0.2050, -0.2495]]],\n",
      "\n",
      "\n",
      "        [[[-0.1266,  0.1427,  0.2202],\n",
      "          [-0.1647,  0.1948, -0.3059],\n",
      "          [-0.0061, -0.1883,  0.2310]]]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1373,  0.2318, -0.0628,  0.0181,  0.0913, -0.1387,  0.1729, -0.2129],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0026, 0.0593, 0.2196, 0.6432, 0.7069, 0.1612, 0.3418, 0.4018],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 5.4682e-02,  5.4092e-02,  1.4727e-02,  1.1943e-02,  4.2909e-02],\n",
      "          [-4.7959e-02, -6.7926e-02, -6.9872e-02, -3.3196e-02,  5.1762e-02],\n",
      "          [ 2.1101e-02, -1.8164e-02, -5.9557e-02,  4.7796e-02, -5.0617e-02],\n",
      "          [-3.5186e-02,  5.3279e-02, -2.9575e-02,  4.3749e-02,  4.6510e-02],\n",
      "          [ 7.7182e-03,  3.7596e-03, -1.4239e-02, -1.3337e-02,  5.5781e-02]],\n",
      "\n",
      "         [[ 3.1965e-02,  2.6707e-02,  4.7971e-02,  5.2579e-02,  3.4719e-03],\n",
      "          [ 5.7467e-02,  3.8749e-02, -6.3511e-03, -6.5464e-02, -7.6144e-03],\n",
      "          [-8.8797e-03, -3.5088e-02,  3.3817e-02, -5.5117e-02,  3.3838e-02],\n",
      "          [-2.3646e-02, -6.0046e-02,  2.0094e-02, -4.2748e-02,  1.8981e-02],\n",
      "          [-2.9825e-02, -2.3310e-02,  5.8064e-02,  5.0368e-02, -5.1207e-02]],\n",
      "\n",
      "         [[ 7.1761e-03, -5.0451e-02,  4.5087e-02,  5.1412e-02, -6.5366e-02],\n",
      "          [-2.1497e-02, -3.3764e-02,  6.4996e-02, -6.5561e-02,  1.0222e-02],\n",
      "          [-3.4016e-02, -3.4780e-02,  6.0227e-03, -3.0317e-02, -1.5622e-02],\n",
      "          [-7.3549e-03, -4.2142e-02, -6.2005e-02,  2.6166e-02, -3.9362e-02],\n",
      "          [-5.2732e-03,  3.7853e-02, -1.9821e-02, -4.5740e-02, -5.3428e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5375e-02,  1.3087e-02, -5.3231e-02,  4.2169e-02,  1.2433e-02],\n",
      "          [-5.9620e-02,  2.7168e-02,  2.6206e-03,  3.2856e-02, -4.0555e-02],\n",
      "          [-5.3562e-02,  5.0545e-02,  5.6351e-02,  1.1064e-02,  7.0690e-02],\n",
      "          [-1.1633e-02, -2.3401e-03,  1.0117e-02, -1.2736e-02,  1.7619e-02],\n",
      "          [ 6.2552e-02,  5.9265e-02,  1.3750e-02, -6.9150e-02, -3.6160e-02]],\n",
      "\n",
      "         [[-6.3568e-02,  2.8465e-03, -5.0277e-02,  2.4564e-02, -4.2658e-02],\n",
      "          [ 2.8439e-02, -1.3251e-02,  5.4138e-02,  6.2769e-02, -5.5569e-02],\n",
      "          [-5.2413e-02, -4.5120e-02,  5.2816e-02, -5.5999e-02,  3.5943e-02],\n",
      "          [ 2.1515e-02,  1.3249e-02,  6.7177e-02,  7.2558e-03,  1.0520e-02],\n",
      "          [ 3.4443e-02, -7.0399e-03,  4.4006e-02, -5.2867e-02,  5.2684e-02]],\n",
      "\n",
      "         [[ 2.2239e-02,  5.3715e-02, -6.2727e-03,  3.7719e-02, -1.8237e-02],\n",
      "          [ 6.0409e-02,  2.7255e-02, -6.3144e-02,  3.6558e-02, -2.5574e-02],\n",
      "          [-7.0642e-02, -3.3510e-02, -7.8583e-03,  5.6315e-02,  1.5308e-02],\n",
      "          [ 4.4862e-02, -5.5683e-02, -2.7525e-02,  1.5975e-02,  6.8774e-02],\n",
      "          [ 4.1337e-02,  6.8352e-02, -5.0047e-02,  1.7889e-03,  2.3995e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.4909e-02,  4.9631e-02,  5.8575e-02,  1.6332e-02, -2.2790e-02],\n",
      "          [ 5.8627e-02,  1.2895e-02,  4.0994e-02, -4.4317e-02, -1.9595e-02],\n",
      "          [-3.8154e-02, -4.9077e-02,  8.8236e-03, -5.3949e-03, -2.3821e-02],\n",
      "          [-2.5445e-02,  2.9414e-02,  6.4972e-02,  1.6288e-02,  4.6387e-02],\n",
      "          [-5.0098e-02, -3.2025e-04, -5.3203e-02,  6.5526e-02,  5.9365e-02]],\n",
      "\n",
      "         [[ 4.5413e-02, -5.9678e-02,  1.3017e-02, -7.8149e-03, -1.1611e-03],\n",
      "          [ 2.3129e-02,  6.7820e-02,  1.8070e-02, -4.4901e-02,  6.5114e-02],\n",
      "          [-6.9450e-02, -5.4564e-02, -2.8759e-02, -2.6084e-02, -1.4177e-02],\n",
      "          [-2.6355e-02,  6.3092e-03,  1.4848e-03, -6.4470e-02, -5.5582e-02],\n",
      "          [-4.6971e-03, -1.2479e-02,  4.5659e-02, -1.7627e-02, -1.0328e-03]],\n",
      "\n",
      "         [[ 6.0311e-02, -2.1720e-02,  2.8512e-02,  4.0434e-02, -5.6037e-02],\n",
      "          [ 3.3892e-02, -1.8441e-02,  7.0443e-02,  8.2519e-03, -3.2260e-02],\n",
      "          [ 4.5074e-02,  1.8080e-02,  5.8184e-02,  7.0407e-03, -1.6685e-02],\n",
      "          [-2.8616e-02,  7.4997e-03, -6.8115e-02, -1.3218e-02,  2.2762e-02],\n",
      "          [-3.2618e-02, -3.1530e-02, -6.3916e-04,  1.7238e-02, -3.1903e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9151e-02,  2.2252e-02,  4.7139e-02, -5.7233e-02,  1.3398e-03],\n",
      "          [ 4.8670e-02,  5.5409e-02, -1.1266e-02, -6.5713e-02, -6.8738e-02],\n",
      "          [ 3.1980e-02,  4.3401e-02,  2.9880e-02, -4.4350e-02, -6.5157e-03],\n",
      "          [ 2.0535e-02,  9.7209e-04,  6.1938e-02, -4.1537e-02,  5.2117e-02],\n",
      "          [ 1.1884e-02, -3.4656e-02, -7.2648e-03, -7.2285e-03,  1.2014e-02]],\n",
      "\n",
      "         [[-3.2367e-02, -5.4286e-02,  2.6476e-02,  5.3794e-02, -9.8519e-03],\n",
      "          [ 5.1854e-02,  6.2865e-02,  2.5696e-02, -6.5202e-02,  1.5747e-02],\n",
      "          [-2.7110e-02, -2.6724e-03, -1.4085e-02, -4.5288e-02, -5.9236e-02],\n",
      "          [ 2.7138e-02,  6.6815e-02,  3.1045e-02, -6.4348e-02,  5.4845e-02],\n",
      "          [-6.6023e-02,  2.0408e-02,  5.6634e-02,  6.9148e-02, -1.3074e-02]],\n",
      "\n",
      "         [[-3.9754e-02,  6.3654e-02, -2.3092e-02, -8.0880e-03, -3.0509e-02],\n",
      "          [ 6.4970e-02, -3.3630e-02,  5.6945e-02, -2.3455e-02,  2.1700e-02],\n",
      "          [-3.1765e-02, -6.8474e-02, -1.2701e-02, -2.3280e-03, -4.7236e-02],\n",
      "          [ 2.2311e-02,  6.4681e-02,  1.9683e-02,  4.9098e-02, -3.4627e-02],\n",
      "          [-3.6056e-02,  5.4801e-02, -3.5190e-02,  3.5203e-03,  6.0736e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8830e-02,  1.5987e-03, -6.6568e-02,  3.2845e-03,  4.3040e-02],\n",
      "          [ 6.9606e-02,  6.7523e-02,  5.0658e-02, -2.7501e-02, -3.0252e-03],\n",
      "          [-5.8289e-02,  3.5986e-02, -3.2136e-02,  6.8136e-02, -4.2498e-02],\n",
      "          [-6.6285e-02, -1.5612e-02,  4.1966e-02, -1.7606e-02,  6.6236e-02],\n",
      "          [ 6.7367e-02, -5.3377e-02,  2.9266e-02, -6.2767e-02,  5.8354e-02]],\n",
      "\n",
      "         [[-6.3375e-02, -5.7625e-02,  2.8447e-02,  3.5876e-02,  4.9335e-02],\n",
      "          [ 2.2699e-02, -6.2855e-02,  3.8045e-02,  1.0630e-02, -4.6418e-02],\n",
      "          [ 6.9261e-02,  4.7984e-02,  4.8797e-02, -2.6972e-03,  5.4706e-02],\n",
      "          [ 2.3251e-02, -4.7412e-02,  2.9563e-02,  3.3133e-02,  7.6783e-04],\n",
      "          [-6.0602e-02, -3.3977e-02,  2.6731e-02, -6.8967e-03, -1.8601e-02]],\n",
      "\n",
      "         [[ 1.2476e-02,  2.9934e-03, -1.9729e-02,  5.4855e-02, -6.1112e-02],\n",
      "          [-5.4572e-02, -1.5133e-02,  4.1886e-02, -2.9046e-02,  2.6728e-02],\n",
      "          [ 2.7474e-03,  2.8776e-02, -6.2485e-02,  3.4613e-02,  4.5501e-02],\n",
      "          [-2.3036e-02,  4.2884e-02, -7.5273e-03,  1.8501e-02, -1.9035e-02],\n",
      "          [-6.5706e-02, -2.6192e-03, -4.7234e-02,  6.5291e-02,  5.3608e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.2959e-05,  2.5655e-02,  2.4729e-02,  5.1883e-02,  3.5019e-02],\n",
      "          [-2.1264e-02,  1.0750e-03, -6.5993e-02,  4.4279e-02, -6.6359e-02],\n",
      "          [ 3.1237e-02,  3.4364e-02,  8.5135e-03, -1.1059e-02,  4.2913e-02],\n",
      "          [ 3.4636e-02,  4.5726e-02, -3.3150e-02,  6.4992e-02,  4.9443e-02],\n",
      "          [ 4.0639e-03, -6.6944e-02,  2.3204e-02, -7.0149e-02,  2.8762e-03]],\n",
      "\n",
      "         [[-3.5990e-03, -5.5505e-02, -4.9269e-02, -1.6305e-02, -1.6276e-02],\n",
      "          [ 5.9193e-02, -5.0916e-02,  6.5140e-02,  8.9055e-03,  5.3763e-02],\n",
      "          [ 4.2829e-02,  1.1399e-02, -3.0733e-02, -6.3821e-02,  1.0029e-02],\n",
      "          [ 6.6992e-02,  2.6444e-02,  5.3118e-03, -5.6327e-02,  3.1302e-02],\n",
      "          [-3.3449e-02, -3.2944e-02,  5.2820e-03, -8.2966e-04, -2.4906e-02]],\n",
      "\n",
      "         [[-1.6038e-02, -4.5160e-02, -1.8911e-02, -3.0853e-03, -3.7248e-02],\n",
      "          [-3.8833e-02,  3.5724e-03,  4.2493e-02,  6.5772e-03,  2.9340e-02],\n",
      "          [-5.3357e-02,  1.6717e-02, -1.4184e-02,  3.0229e-02, -5.1358e-02],\n",
      "          [-6.2695e-02,  3.6447e-02,  6.2363e-02,  4.3205e-02,  3.4491e-02],\n",
      "          [ 2.9753e-02, -4.0011e-02,  8.5564e-03, -4.9740e-02,  5.5950e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.3525e-02, -5.9640e-02,  6.7623e-02,  5.7089e-02, -2.8105e-02],\n",
      "          [-2.9231e-02, -2.5180e-02, -1.9412e-04, -5.2966e-02,  5.8117e-02],\n",
      "          [-6.3891e-02, -2.8968e-02, -6.4094e-02,  6.4285e-02, -3.2738e-02],\n",
      "          [-4.4128e-02, -5.3416e-03, -7.6488e-03, -6.7668e-02, -1.3389e-02],\n",
      "          [-2.9042e-03, -4.6782e-02, -9.0399e-03, -4.0891e-02, -2.5024e-02]],\n",
      "\n",
      "         [[ 2.0813e-03,  4.4014e-02, -6.5632e-02,  5.6324e-02,  3.8201e-02],\n",
      "          [-2.6418e-02,  1.6965e-02,  3.0851e-02, -3.7062e-02,  1.2926e-02],\n",
      "          [-2.7892e-02, -6.1028e-02, -3.0761e-03,  5.1036e-03, -2.9470e-02],\n",
      "          [-5.3388e-02,  5.2275e-02, -7.0037e-02,  5.5849e-02, -2.7475e-02],\n",
      "          [-4.9503e-02,  3.2035e-02, -6.3597e-02,  2.5620e-02, -9.9434e-03]],\n",
      "\n",
      "         [[-2.4794e-02, -3.2294e-02, -4.8728e-02,  5.4644e-02, -3.0666e-02],\n",
      "          [-3.4720e-02,  3.5186e-02, -2.9450e-02,  3.0643e-02, -5.5202e-02],\n",
      "          [ 4.8617e-02, -1.6884e-02,  7.8444e-03, -4.8592e-02, -6.8975e-02],\n",
      "          [ 3.3513e-02,  2.3308e-02, -6.6553e-02,  2.7448e-02, -4.3229e-02],\n",
      "          [ 1.6665e-02,  5.9866e-02,  5.4789e-02, -8.1344e-04, -2.2510e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.0794e-02, -1.5742e-02,  3.2142e-02, -1.8127e-02, -2.1617e-02],\n",
      "          [ 6.1259e-02, -7.0076e-02,  5.2952e-02,  8.5882e-03,  1.7519e-02],\n",
      "          [ 4.6614e-02,  2.0825e-02, -3.0536e-02, -2.6521e-02, -3.9673e-02],\n",
      "          [-3.2380e-02,  4.9200e-02,  4.1666e-02,  5.9102e-02,  4.6410e-02],\n",
      "          [-2.4136e-02, -3.3412e-02, -1.2091e-02,  5.8233e-02, -9.3074e-03]],\n",
      "\n",
      "         [[-6.2657e-02,  2.9434e-02,  3.7250e-02,  4.7971e-02, -2.0991e-02],\n",
      "          [-6.8018e-03,  2.9727e-02,  3.0675e-02, -4.9837e-02,  3.2653e-02],\n",
      "          [-3.5706e-02, -6.1765e-02, -6.0746e-02,  3.3881e-02, -5.0719e-03],\n",
      "          [-2.1644e-02,  4.3381e-02,  3.1659e-02, -4.9560e-02,  1.6814e-03],\n",
      "          [-2.1663e-02,  5.0182e-02,  1.8557e-02,  6.4557e-02,  2.7763e-02]],\n",
      "\n",
      "         [[ 3.2576e-02, -6.9834e-02, -5.7121e-02, -9.3509e-03, -3.7731e-02],\n",
      "          [-5.5066e-02,  4.7829e-02,  4.6075e-02, -2.3224e-02,  1.5868e-02],\n",
      "          [-3.7611e-02, -3.8799e-02,  2.9091e-03,  2.5067e-02,  4.4403e-02],\n",
      "          [ 4.5012e-02,  6.6023e-02, -5.2205e-02,  4.9238e-02,  2.4709e-02],\n",
      "          [ 5.9570e-02, -1.3302e-03,  4.8399e-02,  2.9455e-02, -4.8070e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.3836e-02,  4.2521e-02,  4.6526e-02, -2.9255e-02,  1.0748e-02],\n",
      "          [ 4.3895e-02, -1.7689e-03,  6.9474e-02,  3.5665e-02,  3.3842e-02],\n",
      "          [ 2.3902e-02, -1.5977e-02,  2.7743e-02,  4.2407e-02, -5.8915e-02],\n",
      "          [-6.6527e-02, -2.3513e-02,  4.6253e-02, -1.8427e-02, -2.9988e-02],\n",
      "          [ 1.4637e-02,  3.6203e-02,  5.8361e-02, -6.9469e-02, -1.7440e-02]],\n",
      "\n",
      "         [[-1.1751e-02, -3.7912e-02,  6.8936e-02, -1.5863e-02,  4.8815e-02],\n",
      "          [ 1.6202e-02, -6.2809e-02,  3.2332e-02, -3.7387e-02,  5.2596e-02],\n",
      "          [-5.4830e-02,  6.9209e-02, -3.0440e-02, -3.8127e-02, -1.0836e-02],\n",
      "          [-2.7869e-02, -6.4184e-02,  4.5668e-02, -6.5449e-02,  2.9573e-02],\n",
      "          [-3.3477e-02,  2.8963e-02, -4.8571e-03, -5.6255e-02,  6.4799e-02]],\n",
      "\n",
      "         [[ 6.3418e-02, -3.4622e-02,  6.6791e-02, -6.2944e-02, -4.3304e-03],\n",
      "          [ 3.2329e-03,  5.4166e-02,  1.8589e-02,  5.6553e-02, -2.4106e-03],\n",
      "          [ 6.0799e-02,  4.2147e-02, -1.0400e-02,  4.3626e-02,  5.3134e-02],\n",
      "          [-1.6197e-02, -5.8948e-02, -6.1565e-02,  5.0177e-02, -4.4603e-02],\n",
      "          [ 4.6287e-02, -1.2171e-02, -3.0892e-02, -3.4853e-02, -3.8552e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0248e-02,  2.8564e-02, -7.6362e-03, -7.0009e-02, -5.4305e-03],\n",
      "          [ 4.5826e-02,  3.5651e-02, -5.0641e-02,  6.7429e-02,  5.3823e-02],\n",
      "          [ 4.4082e-03,  4.0950e-04, -1.4190e-02, -6.5810e-02,  4.9189e-02],\n",
      "          [ 6.7869e-02,  2.8442e-02,  9.0369e-04, -3.8210e-02,  4.6170e-02],\n",
      "          [ 5.3056e-02,  1.3544e-02, -2.0617e-02, -6.2113e-04, -3.3019e-02]],\n",
      "\n",
      "         [[-3.6737e-02,  4.6926e-02,  4.3006e-02, -4.0215e-02,  5.8130e-02],\n",
      "          [-1.2242e-02,  2.0836e-02, -1.3331e-02,  8.4506e-03, -2.8938e-02],\n",
      "          [-1.9273e-02, -5.8249e-02,  4.6063e-02,  6.7446e-02,  6.8403e-03],\n",
      "          [ 1.1211e-02,  4.1027e-02,  8.5680e-03,  6.3278e-03, -8.5339e-03],\n",
      "          [ 6.1039e-02, -5.2658e-02, -1.7381e-02,  3.7109e-02,  5.3138e-02]],\n",
      "\n",
      "         [[ 1.0458e-03,  4.1763e-02, -5.9623e-02,  4.8971e-02,  5.4319e-02],\n",
      "          [ 5.6341e-03,  1.8121e-02,  2.8067e-02,  6.3601e-02,  5.2354e-03],\n",
      "          [-1.3062e-02, -4.4094e-02,  8.1426e-03,  5.6454e-02, -7.0482e-02],\n",
      "          [-5.7918e-02, -1.9141e-02,  1.4194e-02, -3.6286e-02, -5.6144e-02],\n",
      "          [-2.7268e-02,  7.0498e-02,  4.3151e-02,  6.9665e-02,  1.1259e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.9992e-02, -2.6579e-02,  4.4761e-02, -5.0001e-02, -6.1417e-02],\n",
      "          [-1.2184e-02,  8.6314e-04,  1.7811e-02,  3.9928e-03,  3.1339e-02],\n",
      "          [ 6.2367e-02, -4.6082e-02,  3.6369e-02,  4.1415e-02, -1.8164e-02],\n",
      "          [ 3.6681e-02,  3.3600e-02, -3.1261e-02, -5.7366e-03,  5.8032e-02],\n",
      "          [-1.0362e-02, -2.1857e-02,  3.0744e-02,  3.2390e-02,  3.3694e-02]],\n",
      "\n",
      "         [[-2.5920e-02,  2.2598e-02, -1.1331e-02,  3.7237e-02, -1.0889e-02],\n",
      "          [ 6.4295e-02, -6.7462e-02,  1.1328e-02,  3.2690e-02, -3.3552e-02],\n",
      "          [-3.1397e-02, -2.5263e-02, -3.5638e-03, -2.1134e-02,  5.0151e-02],\n",
      "          [-4.8703e-04,  6.8165e-02,  5.1611e-02,  1.5052e-02, -3.6616e-03],\n",
      "          [ 1.0531e-02, -5.3719e-02, -3.1608e-02,  4.8726e-02, -5.4638e-02]],\n",
      "\n",
      "         [[-3.7978e-02, -6.8754e-02,  2.2978e-03, -1.9252e-02,  7.5081e-03],\n",
      "          [-3.9215e-02,  1.8077e-02, -1.1669e-02, -4.9817e-02,  5.2075e-02],\n",
      "          [-2.7070e-02,  1.9072e-02,  3.8516e-02, -5.9984e-02, -4.7967e-02],\n",
      "          [-4.3156e-02, -6.8108e-02,  1.2933e-02,  3.1335e-02,  2.1304e-02],\n",
      "          [-2.5520e-02, -5.9410e-02,  2.7440e-02,  4.7491e-02, -5.2023e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1656e-02, -2.5587e-02, -8.6490e-03, -5.1359e-03,  5.2903e-02],\n",
      "          [ 6.3806e-02,  6.7393e-02, -5.5870e-02,  1.5627e-02,  3.3840e-02],\n",
      "          [ 1.5632e-02,  4.7504e-02, -4.3886e-03, -5.1183e-02, -3.6090e-02],\n",
      "          [ 7.1104e-03, -5.7535e-02,  6.7378e-02, -6.7484e-02,  6.3249e-02],\n",
      "          [-3.0311e-02,  1.2856e-02,  4.2313e-02, -3.9354e-02,  3.5679e-02]],\n",
      "\n",
      "         [[-4.0447e-02, -1.0779e-02,  6.2934e-02,  5.1090e-02,  6.6349e-02],\n",
      "          [ 6.8245e-02, -4.6854e-02,  2.6480e-02,  2.4981e-02,  4.1276e-02],\n",
      "          [-2.4971e-02, -4.4213e-02, -7.9361e-03, -4.0915e-02,  8.9440e-03],\n",
      "          [-5.9589e-02,  6.1790e-02,  5.0166e-03, -3.0689e-02,  4.3300e-02],\n",
      "          [-1.3899e-02,  6.6763e-02,  5.3796e-02,  4.2692e-02,  1.2303e-02]],\n",
      "\n",
      "         [[-2.7467e-02, -4.2266e-02,  3.7038e-03,  2.1831e-02, -8.4288e-03],\n",
      "          [ 5.7102e-02, -5.9868e-03,  4.9592e-02, -6.6556e-02, -2.4770e-02],\n",
      "          [ 4.1082e-02,  6.8024e-02,  5.3266e-02, -3.2314e-02, -6.4579e-02],\n",
      "          [ 1.6917e-02, -7.0310e-02,  3.9598e-02,  4.7798e-02, -4.8317e-02],\n",
      "          [-7.0127e-03, -1.6101e-02,  5.3509e-02, -4.5033e-02,  5.3879e-02]]]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0534, -0.0277, -0.0638, -0.0384, -0.0089, -0.0126, -0.0582, -0.0498,\n",
      "         0.0005, -0.0445, -0.0487, -0.0330,  0.0217,  0.0121,  0.0335,  0.0641,\n",
      "        -0.0612, -0.0393, -0.0196,  0.0575,  0.0467,  0.0301, -0.0691,  0.0605,\n",
      "        -0.0693, -0.0596,  0.0061, -0.0459, -0.0069, -0.0681,  0.0277, -0.0115],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.5425, 0.1322, 0.7275, 0.0681, 0.5426, 0.1259, 0.7643, 0.4423, 0.0450,\n",
      "        0.7215, 0.3360, 0.5011, 0.5320, 0.6578, 0.4747, 0.5565, 0.1339, 0.5419,\n",
      "        0.4214, 0.4738, 0.4435, 0.6825, 0.5904, 0.5763, 0.5528, 0.9273, 0.7956,\n",
      "        0.6974, 0.8171, 0.7365, 0.1860, 0.6110], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0084,  0.0176,  0.0193,  ...,  0.0217, -0.0203, -0.0114],\n",
      "        [-0.0044,  0.0241,  0.0154,  ..., -0.0209,  0.0031,  0.0036],\n",
      "        [-0.0238,  0.0195,  0.0190,  ..., -0.0123, -0.0236,  0.0025],\n",
      "        ...,\n",
      "        [-0.0039,  0.0149, -0.0004,  ..., -0.0131,  0.0103,  0.0105],\n",
      "        [-0.0089, -0.0126,  0.0144,  ...,  0.0178, -0.0023, -0.0173],\n",
      "        [ 0.0245,  0.0204, -0.0154,  ...,  0.0006, -0.0065, -0.0234]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.3908e-02,  2.0617e-02,  6.2164e-03, -1.3257e-02,  1.8742e-03,\n",
      "        -9.4095e-03,  5.5289e-03, -2.4956e-03, -3.3117e-03, -4.8355e-03,\n",
      "         2.0920e-02, -8.9940e-03, -1.4067e-02, -6.4367e-03, -1.6583e-02,\n",
      "        -1.6347e-02, -1.2173e-02,  2.0344e-02,  1.6389e-03,  5.4721e-03,\n",
      "         1.2336e-02, -1.5323e-03,  1.1130e-02,  1.6564e-02, -7.3172e-03,\n",
      "        -9.4749e-03, -1.1371e-03, -2.4504e-02, -2.0625e-02,  2.1021e-02,\n",
      "        -1.0686e-02,  2.2242e-02, -1.6642e-02, -9.5044e-03, -7.0974e-03,\n",
      "        -2.1717e-02, -1.6917e-02, -5.5893e-04, -3.1491e-03,  1.7365e-02,\n",
      "        -2.4973e-02,  1.2563e-02, -1.8622e-02,  2.4599e-02, -2.3690e-02,\n",
      "        -1.5645e-02,  1.8825e-02, -6.3973e-03, -2.3664e-03,  1.2543e-02,\n",
      "         5.1358e-03,  5.6843e-04,  1.6803e-02, -2.3409e-02,  3.7435e-03,\n",
      "         9.2354e-03, -2.2664e-03,  1.2334e-02, -7.9116e-03, -1.3661e-02,\n",
      "         1.1548e-02,  1.8351e-02,  1.4015e-02, -1.7167e-02, -2.1280e-02,\n",
      "         2.1021e-02, -1.2592e-02,  1.4521e-02,  2.4777e-02,  2.2424e-02,\n",
      "         1.8777e-02, -4.7645e-03,  1.6290e-02,  1.4671e-02, -2.0981e-02,\n",
      "         1.9618e-02,  4.4254e-03, -1.5720e-02,  2.4736e-02, -2.2058e-03,\n",
      "         2.5057e-02,  1.0820e-02, -5.0448e-03,  4.0362e-03, -4.1594e-03,\n",
      "        -1.6183e-02,  1.8366e-02, -2.3811e-02, -1.5253e-03,  1.7269e-02,\n",
      "         5.2185e-03, -3.7337e-03,  5.0807e-03, -7.0386e-03, -1.9702e-03,\n",
      "        -1.2614e-02,  7.5322e-03, -1.9132e-03, -1.1030e-02,  2.4825e-02,\n",
      "         9.8030e-03, -2.2342e-03,  1.0459e-02, -1.5047e-02, -5.3808e-03,\n",
      "        -1.2722e-02, -9.1163e-03, -5.5254e-03, -2.2142e-02,  1.8785e-02,\n",
      "        -8.5868e-03, -2.3496e-02,  2.1599e-02,  2.5822e-03, -1.2938e-02,\n",
      "        -1.3953e-02,  1.4590e-02,  1.9562e-02,  1.0862e-02, -1.8658e-02,\n",
      "        -1.1794e-02, -8.3160e-03, -8.3225e-03, -1.1928e-02,  4.5772e-04,\n",
      "        -1.2760e-03,  4.9258e-04,  1.6978e-02,  8.0852e-03,  1.3606e-02,\n",
      "         3.3078e-03,  1.8245e-02, -2.1133e-02,  1.8083e-02, -9.1843e-03,\n",
      "        -9.4254e-04,  2.1076e-02, -1.9581e-02, -1.1012e-02, -4.9190e-03,\n",
      "         2.1406e-02,  2.9500e-04,  1.2095e-02,  1.4013e-02, -1.2499e-03,\n",
      "         4.3810e-03,  1.9493e-02,  1.7662e-03, -6.8373e-03,  1.7652e-02,\n",
      "         2.1012e-02, -3.4374e-03,  4.9336e-03,  4.8008e-03, -6.9463e-03,\n",
      "        -1.2222e-02,  1.9091e-02, -1.0561e-02, -1.9731e-02, -1.1331e-02,\n",
      "         8.3239e-03,  1.4954e-02, -2.0021e-02, -2.3584e-02, -2.4888e-02,\n",
      "         2.0501e-02, -2.4362e-02, -1.1273e-03,  3.7446e-03, -1.2447e-02,\n",
      "         1.0366e-02, -2.0758e-02, -1.3765e-02,  1.0703e-02, -1.1703e-02,\n",
      "         1.3593e-02, -4.9125e-03, -6.2169e-03, -2.0902e-02, -1.8364e-02,\n",
      "        -1.2326e-02,  1.6964e-02, -2.2088e-02, -1.5938e-02, -2.3561e-02,\n",
      "         4.5281e-04,  2.4413e-02,  1.7551e-02,  1.9739e-02, -1.4284e-02,\n",
      "        -2.1762e-02,  8.9472e-03, -7.5559e-03,  2.3080e-02,  4.1997e-03,\n",
      "         5.2305e-03, -1.5694e-02,  1.6108e-03, -1.6825e-02,  1.1801e-02,\n",
      "        -1.7010e-02,  1.6153e-02, -1.1160e-02,  2.1952e-02,  9.4048e-03,\n",
      "        -7.6852e-03, -2.3083e-02,  6.8120e-03, -5.2660e-03, -2.9320e-03,\n",
      "         1.8351e-02, -2.0205e-02, -9.3417e-03, -1.1480e-02,  2.4560e-03,\n",
      "         1.7573e-02, -1.3802e-02,  8.5716e-04, -2.1074e-02,  1.9370e-02,\n",
      "         2.6072e-03, -9.0986e-03, -1.0527e-02, -1.9577e-02, -1.8091e-02,\n",
      "         8.4827e-03, -1.9099e-02,  2.3592e-02, -1.6939e-02,  6.8028e-03,\n",
      "         2.3060e-02, -2.3451e-03, -2.0659e-02, -1.9707e-03,  3.7310e-04,\n",
      "        -2.4922e-03,  5.5617e-03,  1.7918e-02,  1.0489e-02, -6.6493e-03,\n",
      "        -3.9734e-04, -1.6048e-02, -1.0428e-02, -9.3243e-03,  1.4566e-03,\n",
      "        -2.8217e-03, -5.5290e-03,  4.9040e-03,  3.8588e-03,  3.9570e-03,\n",
      "         1.0901e-02,  7.5258e-03, -1.0154e-02,  2.5081e-02, -4.8398e-03,\n",
      "         2.3717e-02,  1.1945e-02,  2.1796e-02, -9.5254e-03,  1.3259e-03,\n",
      "        -4.7690e-03, -1.6538e-02, -1.8983e-02,  1.9964e-02,  1.5233e-02,\n",
      "        -1.4884e-02, -1.4822e-02,  1.6923e-02,  2.1923e-02,  2.0465e-02,\n",
      "        -2.2126e-02, -2.4495e-02, -1.8484e-02,  2.3313e-02,  1.2859e-03,\n",
      "        -7.7661e-03,  6.2463e-03,  1.1142e-02, -4.6942e-03,  1.2577e-02,\n",
      "        -1.4512e-02, -1.1338e-03, -2.6645e-03,  3.5042e-03, -1.4038e-02,\n",
      "        -1.0175e-02,  2.3285e-03,  2.0851e-02, -6.1322e-03,  1.5871e-02,\n",
      "         1.8512e-02, -8.2923e-03, -3.6006e-03, -1.5192e-02, -1.1456e-02,\n",
      "         8.7829e-03,  2.2222e-02,  1.9170e-02, -1.0494e-02, -5.9305e-03,\n",
      "        -1.2675e-02, -3.9615e-03, -8.1524e-03,  2.1600e-02, -2.4926e-02,\n",
      "         1.6190e-02, -2.4191e-02, -1.2172e-03, -1.1717e-02,  2.0091e-02,\n",
      "         4.2063e-03,  1.2539e-03, -1.8942e-02,  1.7141e-02,  1.4067e-02,\n",
      "         9.9879e-03,  4.7787e-03,  1.9889e-02,  1.0620e-03, -2.0422e-03,\n",
      "         1.9709e-02, -2.3880e-02, -1.7325e-02, -1.6511e-02,  3.7123e-03,\n",
      "        -1.6358e-02,  4.6696e-03,  1.1303e-02,  2.3153e-02, -4.7304e-03,\n",
      "        -2.0562e-03,  1.4496e-02,  1.9126e-02,  5.3089e-03,  7.4977e-03,\n",
      "         1.4737e-02, -2.5463e-03, -2.4445e-02, -1.0736e-02,  2.0434e-02,\n",
      "         5.5625e-03, -2.2305e-02, -3.3891e-03, -1.6642e-02,  7.8522e-03,\n",
      "         6.9537e-03,  1.4988e-02,  2.5201e-02, -2.4742e-02, -7.0347e-03,\n",
      "        -8.9487e-03,  2.8007e-05, -5.0339e-03, -2.2383e-02, -2.0808e-02,\n",
      "         3.8813e-03,  1.3667e-02,  8.0279e-03, -8.2169e-03, -7.5819e-03,\n",
      "         2.0786e-03, -2.4889e-02,  2.0203e-02, -1.0624e-02,  1.1033e-02,\n",
      "         1.2755e-02, -5.0851e-03,  2.4555e-02, -3.4367e-03, -8.0132e-03,\n",
      "         4.6237e-03, -1.9029e-02,  2.2695e-02, -1.6523e-02,  3.3176e-03,\n",
      "        -1.7762e-02,  2.2363e-02, -1.6862e-02,  1.1349e-03, -2.7958e-03,\n",
      "        -1.1696e-02,  1.9188e-02,  2.7074e-04,  1.6830e-02, -4.0723e-03,\n",
      "         6.4883e-03,  1.8308e-02,  2.5209e-02, -1.9474e-03, -2.3907e-02,\n",
      "         1.7178e-02, -1.9891e-03,  2.1867e-02, -9.2720e-03, -1.8257e-02,\n",
      "        -1.9014e-02, -1.6491e-02, -1.5631e-02,  1.4271e-02, -6.6609e-03,\n",
      "        -1.6284e-02, -1.7557e-02,  1.2078e-03, -1.9208e-02, -2.4896e-02,\n",
      "         8.4343e-03,  1.8589e-02,  3.2859e-03,  1.4946e-03,  2.1628e-02,\n",
      "         2.8845e-03,  1.9494e-02,  1.8305e-02, -1.2261e-02, -1.2938e-02,\n",
      "        -5.0957e-03, -2.6814e-03,  5.8883e-03, -1.1212e-02,  2.4927e-02,\n",
      "         1.3827e-03,  1.3361e-02,  2.6826e-04,  1.3770e-02,  1.3128e-02,\n",
      "         4.8808e-03, -9.8853e-03,  1.7631e-02,  8.9612e-03,  1.2220e-02,\n",
      "         6.0103e-03, -5.8127e-03, -2.2259e-02, -1.2190e-02, -9.1335e-03,\n",
      "         2.0654e-03, -1.1659e-02, -2.6051e-03, -9.0544e-03,  1.1704e-02,\n",
      "         1.1244e-02,  1.4998e-02, -1.7915e-02,  2.3461e-02,  1.1965e-02,\n",
      "         9.1655e-03, -3.3369e-03, -2.3908e-02,  2.9617e-04,  2.2990e-02,\n",
      "         3.1313e-03, -1.3779e-02, -2.2621e-02, -1.5475e-02,  2.1368e-02,\n",
      "         1.7620e-02, -1.3214e-02, -1.0929e-02,  1.6694e-02, -9.3153e-03,\n",
      "         2.2717e-02,  3.7370e-03, -1.5697e-03, -3.4899e-03,  2.0707e-02,\n",
      "        -2.4231e-02, -1.1393e-02,  2.4980e-03, -1.2578e-02, -1.1025e-02,\n",
      "        -8.0718e-03,  9.0259e-03, -5.7326e-03, -1.3342e-02, -4.6181e-03,\n",
      "        -1.1765e-02,  1.0778e-02, -2.0538e-02,  1.7541e-02, -1.2004e-02,\n",
      "        -7.8565e-03, -4.2146e-03, -2.0678e-02, -2.2319e-02, -3.8796e-03,\n",
      "         1.6568e-02,  8.3306e-03,  3.9863e-03,  1.3743e-03,  9.1975e-03,\n",
      "        -7.3240e-03,  1.0885e-03, -2.0925e-02, -5.4358e-03, -1.1848e-02,\n",
      "        -1.5501e-02, -1.1960e-02, -1.7924e-02, -1.9208e-02,  8.5230e-03,\n",
      "        -1.5751e-02,  7.1543e-03,  7.1227e-03, -1.7899e-02,  1.5618e-02,\n",
      "         2.4275e-02, -2.2982e-02,  5.4649e-04,  1.0196e-02, -1.3251e-02,\n",
      "         8.1857e-03, -1.8901e-02,  2.2658e-03, -1.5322e-02,  8.6721e-03,\n",
      "        -7.7278e-03,  4.0163e-03,  1.3541e-02,  1.1534e-02,  9.4765e-03,\n",
      "        -3.3844e-03,  1.7903e-02, -1.1129e-02,  3.1508e-03,  7.7549e-03,\n",
      "         1.4126e-02,  1.7655e-02, -1.2923e-02,  9.9076e-03,  8.0630e-03,\n",
      "        -1.4638e-02,  2.1139e-02,  2.4678e-02,  4.6249e-04,  1.2081e-02,\n",
      "         9.8988e-03,  1.8371e-02,  9.9422e-03, -2.0215e-02,  4.4589e-03,\n",
      "         6.4805e-03,  1.2819e-02,  6.6769e-03, -4.4888e-03, -1.1844e-02,\n",
      "        -1.6001e-02, -1.3266e-02, -1.8602e-02, -1.3144e-02,  1.7735e-02,\n",
      "         1.5727e-02, -2.2963e-02,  1.5771e-02,  1.1152e-03,  1.7098e-02,\n",
      "        -1.0283e-02, -2.0722e-02,  1.1136e-02, -9.9890e-03, -1.5589e-03,\n",
      "        -1.3274e-02, -7.8308e-03,  2.4355e-04,  1.8403e-02,  1.9746e-02,\n",
      "        -9.4373e-03,  9.9105e-03, -2.3626e-02, -1.8287e-02, -2.2111e-02,\n",
      "        -1.2629e-02,  4.3325e-03, -5.5414e-03,  2.0185e-02, -1.5078e-02,\n",
      "        -2.1816e-02,  2.0533e-02,  2.1877e-02,  2.0772e-02, -2.0188e-02,\n",
      "        -1.2621e-02,  1.7092e-02, -2.4570e-02, -2.3004e-02,  2.8548e-03,\n",
      "        -2.2284e-02,  1.1101e-02,  2.1172e-02, -1.3491e-02, -5.0808e-03,\n",
      "        -2.2220e-02, -2.2628e-02, -1.0091e-02,  1.7658e-02,  9.8924e-03,\n",
      "         1.0127e-02, -2.8123e-03, -2.3190e-02, -2.3862e-02,  5.7951e-04],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0327, -0.0016,  0.0354,  ..., -0.0208,  0.0227, -0.0273],\n",
      "        [-0.0375, -0.0270, -0.0390,  ..., -0.0251, -0.0027, -0.0340],\n",
      "        [-0.0090, -0.0160,  0.0146,  ...,  0.0212,  0.0230,  0.0291],\n",
      "        ...,\n",
      "        [-0.0018,  0.0283,  0.0008,  ..., -0.0396, -0.0232,  0.0042],\n",
      "        [-0.0394,  0.0321, -0.0381,  ..., -0.0366, -0.0346,  0.0140],\n",
      "        [-0.0222, -0.0144,  0.0378,  ..., -0.0048, -0.0069,  0.0194]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0265,  0.0127, -0.0127,  0.0316,  0.0318,  0.0355, -0.0076,  0.0236,\n",
      "        -0.0299,  0.0255], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from classes.models.CNN import CNN\n",
    "from classes.optim import SGD\n",
    "\n",
    "torch.manual_seed(47)\n",
    "model=CNN()\n",
    "CUDA=torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    model=model.cuda()\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=SGD.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "for w in model.parameters():\n",
    "    print w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100, Train Loss: 2.21505117416, Test Accuracy:23%\n",
      "Iteration: 200, Train Loss: 2.1241941452, Test Accuracy:40%\n",
      "Iteration: 300, Train Loss: 1.97664320469, Test Accuracy:51%\n",
      "Iteration: 400, Train Loss: 1.88949000835, Test Accuracy:59%\n",
      "Iteration: 500, Train Loss: 1.75790035725, Test Accuracy:63%\n",
      "Iteration: 600, Train Loss: 1.60443282127, Test Accuracy:66%\n",
      "Iteration: 700, Train Loss: 1.44357860088, Test Accuracy:69%\n",
      "Iteration: 800, Train Loss: 1.34106326103, Test Accuracy:72%\n",
      "Iteration: 900, Train Loss: 1.26338994503, Test Accuracy:74%\n",
      "Iteration: 1000, Train Loss: 1.17310547829, Test Accuracy:77%\n",
      "Iteration: 1100, Train Loss: 1.11943435669, Test Accuracy:78%\n",
      "Iteration: 1200, Train Loss: 0.966437578201, Test Accuracy:79%\n",
      "Iteration: 1300, Train Loss: 0.949402868748, Test Accuracy:80%\n",
      "Iteration: 1400, Train Loss: 1.00470256805, Test Accuracy:82%\n",
      "Iteration: 1500, Train Loss: 0.802988350391, Test Accuracy:82%\n",
      "Iteration: 1600, Train Loss: 0.759935617447, Test Accuracy:83%\n",
      "Iteration: 1700, Train Loss: 0.770926892757, Test Accuracy:84%\n",
      "Iteration: 1800, Train Loss: 0.643255054951, Test Accuracy:84%\n",
      "Iteration: 1900, Train Loss: 0.575110852718, Test Accuracy:85%\n",
      "Iteration: 2000, Train Loss: 0.620120763779, Test Accuracy:86%\n",
      "Iteration: 2100, Train Loss: 0.520125329494, Test Accuracy:87%\n",
      "Iteration: 2200, Train Loss: 0.525178134441, Test Accuracy:87%\n",
      "Iteration: 2300, Train Loss: 0.512047946453, Test Accuracy:88%\n",
      "Iteration: 2400, Train Loss: 0.739300906658, Test Accuracy:88%\n",
      "Iteration: 2500, Train Loss: 0.513439118862, Test Accuracy:88%\n",
      "Iteration: 2600, Train Loss: 0.560805082321, Test Accuracy:88%\n",
      "Iteration: 2700, Train Loss: 0.487911760807, Test Accuracy:89%\n",
      "Iteration: 2800, Train Loss: 0.417113184929, Test Accuracy:89%\n",
      "Iteration: 2900, Train Loss: 0.373699575663, Test Accuracy:90%\n",
      "Iteration: 3000, Train Loss: 0.460410714149, Test Accuracy:90%\n",
      "Iteration: 3100, Train Loss: 0.537450969219, Test Accuracy:90%\n",
      "Iteration: 3200, Train Loss: 0.550259232521, Test Accuracy:91%\n",
      "Iteration: 3300, Train Loss: 0.461003065109, Test Accuracy:90%\n",
      "Iteration: 3400, Train Loss: 0.293924212456, Test Accuracy:91%\n",
      "Iteration: 3500, Train Loss: 0.337122052908, Test Accuracy:91%\n",
      "Iteration: 3600, Train Loss: 0.340097308159, Test Accuracy:91%\n",
      "Iteration: 3700, Train Loss: 0.320724457502, Test Accuracy:91%\n",
      "Iteration: 3800, Train Loss: 0.342043608427, Test Accuracy:92%\n",
      "Iteration: 3900, Train Loss: 0.381400346756, Test Accuracy:92%\n",
      "Iteration: 4000, Train Loss: 0.528478384018, Test Accuracy:92%\n",
      "Iteration: 4100, Train Loss: 0.345593959093, Test Accuracy:92%\n",
      "Iteration: 4200, Train Loss: 0.334844082594, Test Accuracy:92%\n",
      "Iteration: 4300, Train Loss: 0.367409676313, Test Accuracy:92%\n",
      "Iteration: 4400, Train Loss: 0.215079218149, Test Accuracy:93%\n",
      "Iteration: 4500, Train Loss: 0.346615672112, Test Accuracy:92%\n",
      "Iteration: 4600, Train Loss: 0.445124745369, Test Accuracy:93%\n",
      "Iteration: 4700, Train Loss: 0.271112620831, Test Accuracy:93%\n",
      "Iteration: 4800, Train Loss: 0.279741704464, Test Accuracy:93%\n",
      "Iteration: 4900, Train Loss: 0.280672252178, Test Accuracy:93%\n",
      "Iteration: 5000, Train Loss: 0.19194753468, Test Accuracy:93%\n",
      "Iteration: 5100, Train Loss: 0.238965779543, Test Accuracy:93%\n",
      "Iteration: 5200, Train Loss: 0.30546978116, Test Accuracy:93%\n",
      "Iteration: 5300, Train Loss: 0.244108319283, Test Accuracy:93%\n",
      "Iteration: 5400, Train Loss: 0.243693470955, Test Accuracy:93%\n",
      "Iteration: 5500, Train Loss: 0.205087065697, Test Accuracy:94%\n",
      "Iteration: 5600, Train Loss: 0.361444652081, Test Accuracy:94%\n",
      "Iteration: 5700, Train Loss: 0.238153547049, Test Accuracy:94%\n",
      "Iteration: 5800, Train Loss: 0.22742292285, Test Accuracy:94%\n",
      "Iteration: 5900, Train Loss: 0.272917360067, Test Accuracy:94%\n",
      "Iteration: 6000, Train Loss: 0.259065181017, Test Accuracy:94%\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "iteration=0\n",
    "for epoch in range(epochs):\n",
    "  for i, (images,labels) in enumerate(train_load):\n",
    "    iteration+=1\n",
    "    if CUDA:\n",
    "      images =Variable(images.cuda())\n",
    "      labels =Variable(labels.cuda())\n",
    "    else:\n",
    "      images =Variable(images)\n",
    "      labels =Variable(labels)\n",
    "      \n",
    "    optimizer.zero_grad()\n",
    "    outputs=model(images)\n",
    "    loss=loss_function(outputs,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(i+1)%100 ==0:\n",
    "        correct =0\n",
    "        total =0\n",
    "        for images,labels in test_load:\n",
    "            if CUDA:\n",
    "              images =Variable(images.cuda())\n",
    "            else:\n",
    "              images =Variable(images)\n",
    "\n",
    "            outputs=model(images)\n",
    "            _,predicted=torch.max(outputs.data,1)\n",
    "            total+=labels.size(0)\n",
    "            if CUDA:\n",
    "              correct += (predicted.cpu()==labels.cpu()).sum()\n",
    "            else:\n",
    "              correct += (predicted==labels).sum()\n",
    "\n",
    "        accuracy = 100 *correct/total\n",
    "        print(\"Iteration: {}, Train Loss: {}, Test Accuracy:{}%\".format(iteration, loss.item(),accuracy))\n",
    "        \n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will kill the kernel and will free memory on GPU for others to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration=0\n",
    "trainloss_list=[]\n",
    "i=0\n",
    "for epoch in range(epochs):\n",
    "  #running_loss=0.0\n",
    "  for i, (images,labels) in enumerate(train_load): \n",
    "    iteration+=1\n",
    "    if CUDA:\n",
    "      images =Variable(images.cuda())\n",
    "      labels =Variable(labels.cuda())\n",
    "    else:\n",
    "      images =Variable(images)\n",
    "      labels =Variable(labels)\n",
    "    \n",
    "    if i% (len(train_load)/5) == 0:\n",
    "        train_loss=computeErrorForWholeDataset(train_load)\n",
    "        #test_loss=computeErrorForWholeDataset(test_load)  # compute errors train and test .....\n",
    "        train_loss_list=[].append(train_loss)\n",
    "        print train_loss\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs=model(images)\n",
    "    loss=loss_function(outputs,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(\"Finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 Anaconda",
   "language": "python",
   "name": "python2anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
